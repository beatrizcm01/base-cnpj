{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, warnings, time, re, zipfile, requests, shutil\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\XXXXXXXX\\\\XXXXXXXX\\\\XXXXXXXX'\n",
    "\n",
    "folders_list = os.listdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scrapping\n",
    "Download de arquivos .zip contidos na página da Web fornecida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_url = input('Type here the url of the page to be scrapped: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(input_url)\n",
    "soup = bs(page.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# listando todas as urls da página que contém um arquivo .zip para download\n",
    "\n",
    "urls_list = list()\n",
    "\n",
    "for link in soup.find_all('a', href=re.compile(\".zip$\")):\n",
    "    hyperlink = link.get('href')\n",
    "    urls_list.append(f'{input_url}/{hyperlink}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that downloads a file in a given url\n",
    "\n",
    "def download_file(url):\n",
    "    local_filename = url.split('/')[-1]\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(local_filename, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192): \n",
    "                f.write(chunk)\n",
    "    return local_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download of file in http://200.152.38.155/CNPJ/Cnaes.zip: successfull \n",
      "\n",
      "Download of file in http://200.152.38.155/CNPJ/Empresas0.zip: successfull \n",
      "\n",
      "Download of file in http://200.152.38.155/CNPJ/Empresas1.zip: successfull \n",
      "\n",
      "Download of file in http://200.152.38.155/CNPJ/Empresas2.zip: successfull \n",
      "\n",
      "Download of file in http://200.152.38.155/CNPJ/Empresas3.zip: successfull \n",
      "\n",
      "Download of file in http://200.152.38.155/CNPJ/Empresas4.zip: successfull \n",
      "\n",
      "Download of file in http://200.152.38.155/CNPJ/Empresas5.zip: successfull \n",
      "\n",
      "Download of file in http://200.152.38.155/CNPJ/Empresas6.zip: successfull \n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for i in range(0, len(urls_list)):\n",
    "    download_file(urls_list[i])\n",
    "    print(f'Download do arquivo no link: {urls_list[i]} feito com sucesso! \\n')\n",
    "    \n",
    "end = time.time() - start\n",
    "duration = time.strftime(\"%H:%M:%S\",time.gmtime(end))\n",
    "print(f'Download dos arquivos finalizado. \\nTempo de execução: {duration}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extração dos arquivos .zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função que extrai cada .zip em uma pasta de mesmo nome\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "def unzip_batch(path):\n",
    "    for root, dirs, files in os.walk(path, topdown=False):\n",
    "        zip_files = list(filter(lambda file: file.endswith('.zip'), folders_list))\n",
    "        for file in zip_files:\n",
    "            file_path = f'{path}\\\\{file}'\n",
    "            folder_name = file_path.replace('.zip', '')\n",
    "            with zipfile.ZipFile(file_path,\"r\") as zip_ref:\n",
    "                zip_ref.extractall(folder_name)\n",
    "                print(f'O arquivo {file} foi descompactado com sucesso! \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file Cnaes.zip was extracted with success! \n",
      "\n",
      "The file Dados_Abertos.zip was extracted with success! \n",
      "\n",
      "The file Empresas0.zip was extracted with success! \n",
      "\n",
      "The file Empresas1.zip was extracted with success! \n",
      "\n",
      "The file Empresas2.zip was extracted with success! \n",
      "\n",
      "The file Empresas3.zip was extracted with success! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "unzip_batch(path)\n",
    "\n",
    "end = time.time() - start\n",
    "duration = time.strftime(\"%H:%M:%S\",time.gmtime(end))\n",
    "print(f'Extração dos arquivos finalizada. \\nTempo de execução: {duration}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renomeando os arquivos .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extração dos arquivos finalizada. \n",
      "Tempo de execução: \n",
      "00:00:00.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for root, dirs, files in os.walk(path, topdown=False):\n",
    "    for folder in dirs:\n",
    "        folder_path = os.path.join(root, folder)\n",
    "        files = os.listdir(folder_path)\n",
    "        files_filter = list(filter(lambda file: file.endswith('CSV') or file.endswith('ESTABELE'), files))\n",
    "        #print(files_filter)\n",
    "        for file in files_filter:\n",
    "            old_file_path = f'{folder_path}\\\\{file}'\n",
    "            new_file_path = f'{folder_path}\\\\{folder}.csv'\n",
    "            os.rename(old_file_path, new_file_path)\n",
    "            print(f'O arquivo {file} foi renomeado com sucesso! \\n')\n",
    "            \n",
    "end = time.time() - start\n",
    "duration = time.strftime(\"\\n%H:%M:%S\",time.gmtime(end))\n",
    "print(f'Todos os arquivos foram renomeados. \\nTempo de execução: {duration}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrupando arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_folders = ['Empresas', 'Estabelecimentos', 'Socios']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando novas pastas para agrupar os arquivos relacionados\n",
    "\n",
    "for name in new_folders:\n",
    "    if not os.path.exists(f'{path}\\\\{name}'):\n",
    "        os.makedirs(f'{path}\\\\{name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_batch(folders_list):\n",
    "        for root, dirs, files in os.walk(path, topdown=False):\n",
    "            for file in files:\n",
    "                for name in new_folders:\n",
    "                    grouped_files = list(filter(lambda file: re.match(name, file) and file.endswith('.csv'), files))\n",
    "                    for file in grouped_files:\n",
    "                        old_folder_path = os.path.join(root, file)\n",
    "                        new_folder_path = f'{path}\\\\{name}\\\\{file}'\n",
    "                        shutil.move(old_folder_path, new_folder_path)\n",
    "            print(f'O arquivo {file} foi movido com sucesso! \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_batch(new_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removendo pastas vazias em que os .csv foram extraídos\n",
    "\n",
    "for name in new_folders:\n",
    "    for i in range(0, 10):\n",
    "        if os.path.exists(f'{path}\\\\{name}{i}'):\n",
    "            shutil.rmtree(f'{path}\\\\{name}{i}')\n",
    "            print(f'A pasta vazia {name}{i} foi removida com sucesso! \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformando .csv em .parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = input('Insira o nome da pasta que deseja acessar: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definindo nome das colunas de cada arquivo\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "colunas = {\n",
    "    'Empresas' : ['cnpj_basico', 'razao_social', 'natureza_juridica', 'qualificacao_responsavel', 'capital_social',\n",
    "                  'porte_empresa', 'ente_federativo_responsavel'],\n",
    "    \n",
    "    'Estabelecimentos' : ['cnpj_basico','cnpj_ordem','cnpj_dv','identificador_matriz_filial','nome_fantasia',\n",
    "                          'situacao_cadastral','data_situacao_cadastral','motivo_situacao_cadastral',\n",
    "                          'nome_cidade_exterior','pais','data_inicio_atividade','cnae_fiscal_principal',\n",
    "                          'cnae_fiscal_secundaria','tipo_logradouro','logradouro','numero','complemento',\n",
    "                          'bairro','cep','uf','municipio','ddd_1','telefone_1','ddd_2','telefone_2','ddd_fax',\n",
    "                          'fax','correio_eletronico','situacao_especial','data_situacao_especial'],\n",
    "    \n",
    "    'Socios' : ['cnpj_basico','identificador_socio','nome_socio_razao_social','cpf_cnpj_socio','qualificacao_socio',\n",
    "                'data_entrada_sociedade','pais','representante_legal','nome_do_representante',\n",
    "                'qualificacao_representante_legal','faixa_etaria'],\n",
    "    \n",
    "    'Simples' : ['cnpj_basico','opcao_pelo_simples','data_opcao_simples','data_exclusao_simples','opcao_mei',\n",
    "                 'data_opcao_mei','data_exclusao_mei'],\n",
    "    \n",
    "    'Cnaes': ['codigo', 'descricao'],\n",
    "    \n",
    "    'Motivos': ['codigo', 'descricao'],\n",
    "    \n",
    "    'Municipios' : ['codigo', 'descricao'],\n",
    "    \n",
    "    'Naturezas' : ['codigo', 'descricao'],\n",
    "    \n",
    "    'Paises' : ['codigo', 'descricao'],\n",
    "    \n",
    "    'Qualificacoes': ['codigo', 'descricao']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "input_path = f'{path}\\\\{input_folder}'\n",
    "os.listdir(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion of the file Estabelecimentos0.csv to parquet: successful\n",
      "Creation of the sample file C:\\Users\\menezebe\\OneDrive - Merck Sharp & Dohme LLC\\Documents\\db_cnpj\\data_renamed\\Estabelecimentos\\Estabelecimentos0_min.parquet: successful\n",
      "\n",
      "Conversion of the file Estabelecimentos1.csv to parquet: successful\n",
      "Creation of the sample file C:\\Users\\menezebe\\OneDrive - Merck Sharp & Dohme LLC\\Documents\\db_cnpj\\data_renamed\\Estabelecimentos\\Estabelecimentos1_min.parquet: successful\n",
      "\n",
      "Conversion of the file Estabelecimentos2.csv to parquet: successful\n",
      "Creation of the sample file C:\\Users\\menezebe\\OneDrive - Merck Sharp & Dohme LLC\\Documents\\db_cnpj\\data_renamed\\Estabelecimentos\\Estabelecimentos2_min.parquet: successful\n",
      "\n",
      "Conversion of the file Estabelecimentos3.csv to parquet: successful\n",
      "Creation of the sample file C:\\Users\\menezebe\\OneDrive - Merck Sharp & Dohme LLC\\Documents\\db_cnpj\\data_renamed\\Estabelecimentos\\Estabelecimentos3_min.parquet: successful\n",
      "\n",
      "Conversion of the file Estabelecimentos4.csv to parquet: successful\n",
      "Creation of the sample file C:\\Users\\menezebe\\OneDrive - Merck Sharp & Dohme LLC\\Documents\\db_cnpj\\data_renamed\\Estabelecimentos\\Estabelecimentos4_min.parquet: successful\n",
      "\n",
      "Conversion of the file Estabelecimentos5.csv to parquet: successful\n",
      "Creation of the sample file C:\\Users\\menezebe\\OneDrive - Merck Sharp & Dohme LLC\\Documents\\db_cnpj\\data_renamed\\Estabelecimentos\\Estabelecimentos5_min.parquet: successful\n",
      "\n",
      "Conversion of the file Estabelecimentos6.csv to parquet: successful\n",
      "Creation of the sample file C:\\Users\\menezebe\\OneDrive - Merck Sharp & Dohme LLC\\Documents\\db_cnpj\\data_renamed\\Estabelecimentos\\Estabelecimentos6_min.parquet: successful\n",
      "\n",
      "Conversion of the file Estabelecimentos7.csv to parquet: successful\n",
      "Creation of the sample file C:\\Users\\menezebe\\OneDrive - Merck Sharp & Dohme LLC\\Documents\\db_cnpj\\data_renamed\\Estabelecimentos\\Estabelecimentos7_min.parquet: successful\n",
      "\n",
      "Conversion of the file Estabelecimentos8.csv to parquet: successful\n",
      "Creation of the sample file C:\\Users\\menezebe\\OneDrive - Merck Sharp & Dohme LLC\\Documents\\db_cnpj\\data_renamed\\Estabelecimentos\\Estabelecimentos8_min.parquet: successful\n",
      "\n",
      "Conversion of the file Estabelecimentos9.csv to parquet: successful\n",
      "Creation of the sample file C:\\Users\\menezebe\\OneDrive - Merck Sharp & Dohme LLC\\Documents\\db_cnpj\\data_renamed\\Estabelecimentos\\Estabelecimentos9_min.parquet: successful\n",
      "\n",
      "Finalizada a geração dos arquivos.\n",
      "Tempo de execução: 00:31:44.\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(input_path, topdown=False):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            \n",
    "            coluna_temp = colunas.get(re.sub(r'[0-9]', '',file.replace('.csv',''))) #Colunas para o df, conforme o arquivo\n",
    "            df = pd.read_csv(file_path, sep=';',\n",
    "                             skiprows=0,\n",
    "                             header=None,\n",
    "                             encoding= \"ISO-8859-1\",\n",
    "                             dtype = 'object')\n",
    "            df = df.where(df.notnull(), 'N/A')\n",
    "            df.columns = df.columns.astype(str)\n",
    "            df.columns = coluna_temp\n",
    "            df_min = df.head(5)\n",
    "            \n",
    "            parquet_path = file_path.replace('.csv', '.parquet')\n",
    "            parquet_min_path = parquet_path.replace('.parquet', '_min.parquet')\n",
    "            \n",
    "            if os.path.exists(parquet_path):\n",
    "                os.remove(parquet_path)\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            if os.path.exists(parquet_min_path):\n",
    "                os.remove(parquet_min_path)\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            df.to_parquet(parquet_path)\n",
    "            df_min.to_parquet(parquet_min_path, index=False)\n",
    "            \n",
    "            print(f'Conversão do arquivo {file} para parquet bem sucedida!')\n",
    "            print(f'Criação do arquivo {file.replace('.csv', '_min.parquet')} bem sucedida \\n')\n",
    "            print('')\n",
    "\n",
    "end = time.time() - start\n",
    "duration = time.strftime(\"%H:%M:%S\",time.gmtime(end))\n",
    "print(f'Finalizada a geração dos arquivos.\\nTempo de execução: {duration}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checando se todos os arquivos foram devidamente criados\n",
    "\n",
    "for folder in folders_list:\n",
    "    files = os.listdir(f'{path\\}\\\\{folder}')\n",
    "    print(f'Folder: {folder}')\n",
    "    print('------------------------------------------')\n",
    "    for file in files:\n",
    "        print(file)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This file is OK.\n",
      "This file is OK.\n",
      "File Motivos.parquet_min removed with success!\n"
     ]
    }
   ],
   "source": [
    "# isso aqui é apenas para eu excluir alguns arquivos que criei errados\n",
    "\n",
    "for root, dirs, files in os.walk(path, topdown=False):\n",
    "    for file in files:\n",
    "        if file.endswith('.parquet_min'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            os.remove(file_path)\n",
    "            print(f'File {file} removed with success!')\n",
    "        else:\n",
    "            print(\"This file is OK.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
